{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mernesteze-eng/gpq/blob/master/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Get started with Chirp 3 HD voices using Text-to-Speech\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Faudio%2Fspeech%2Fgetting-started%2Fget_started_with_chirp_3_hd_voices.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_3_hd_voices.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |\n",
        "| [Ivan Nardini](https://github.com/inardini) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces [Chirp 3 HD Voices](https://cloud.google.com/text-to-speech/docs/chirp3-hd), which are Google Cloud's latest advancement in Text-to-Speech (TTS) technology.\n",
        "\n",
        "These voices, powered by state-of-the-art large language models (LLMs), offer a significantly improved level of realism and emotional expressiveness.\n",
        "\n",
        "Chirp 3 HD voices provide high-fidelity audio and natural-sounding speech, complete with human-like intonation and pauses. They are available on the Vertex AI platform and are designed for various uses like, voice assistants, audiobooks, and customer service applications.\n",
        "\n",
        "There are currently eight distinct voice options(4 male, 4 female) available in 31 languages.\n",
        "\n",
        "In this tutorial, you learn how to:\n",
        "\n",
        "- How to synthesize speech using real-time (online) processing\n",
        "- How to synthesize speech using streaming processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Text-to-Speech SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e73_ZgKWYedz",
        "outputId": "2d9dfc1a-3844-4fe8-d047-db5ae558caba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "ffmpeg installed successfully on Linux.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Detect the operating system\n",
        "os=$(uname -s)\n",
        "\n",
        "if [[ \"$os\" == \"Linux\" ]]; then\n",
        "  # Linux installation\n",
        "  sudo apt update -y -qq\n",
        "  sudo apt install ffmpeg -y -qq\n",
        "  echo \"ffmpeg installed successfully on Linux.\"\n",
        "elif [[ \"$os\" == \"Darwin\" ]]; then\n",
        "  # macOS installation\n",
        "  if command -v brew &> /dev/null; then\n",
        "    brew install ffmpeg\n",
        "    if [[ $? -eq 0 ]]; then\n",
        "        echo \"ffmpeg installed successfully on macOS using Homebrew.\"\n",
        "    else\n",
        "        echo \"Error installing ffmpeg on macOS using Homebrew.\"\n",
        "    fi\n",
        "  else\n",
        "    echo \"Homebrew is not installed. Please install Homebrew and try again.\"\n",
        "  fi\n",
        "else\n",
        "  echo \"Unsupported operating system: $os\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "outputId": "9edaf3f3-337d-4b1c-cefb-c8ffd756ade7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/188.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/188.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-cloud-texttospeech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize SDK\n",
        "\n",
        "To get started using the Text-to-Speech API, you must have an existing Google Cloud project and [enable the API](https://console.cloud.google.com/flows/enableapi?apiid=texttospeech.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
        "\n",
        "Please note the **available regions** for Chirp 3, see [documentation](https://cloud.google.com/text-to-speech/docs/endpoints)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WIQyBhAn_9tK"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"numeric-abbey-416701\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "TTS_LOCATION = \"global\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "76915236b1c9",
        "outputId": "2f4d7d3d-3c72-4b55-dd2f-a717ca8ddc73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m INVALID_ARGUMENT: Request contains an invalid argument.\n",
            "Are you sure you wish to set property [core/project] to None?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.config.set) The project property must be set to a valid project ID, not the project name [None]\n",
            "To set your project, run:\n",
            "\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\n",
            "or to unset it, run:\n",
            "\n",
            "  $ gcloud config unset project\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.auth.application-default.set-quota-project) Application default credentials have not been set up. Run $ gcloud auth application-default login to set it up first.\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=LNU0GMFMI1QjkbKkj0uhCegOYWVpZA&prompt=consent&token_usage=remote&access_type=offline&code_challenge=wNt_sXyLO22Ofc30Tc3k-8UF8mNmexz9rZM3L5WgtJ8&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab_5qllWexPv_x_ctxLaM1tbbXM6Az0DWeso4n4qahA-QY7mbEeC4LoxNG4UHnu9Ve1a1g\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "! gcloud config set project {PROJECT_ID}\n",
        "! gcloud auth application-default set-quota-project {PROJECT_ID}\n",
        "! gcloud auth application-default login -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qqm0OQpAYCph"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Iterator\n",
        "import re\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import texttospeech_v1beta1 as texttospeech\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP8GBj3tBAC1"
      },
      "source": [
        "### Set constants\n",
        "\n",
        "Initiate the API endpoint and the text to speech client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rXTVeU1uBBqY",
        "outputId": "e11901ea-6076-414a-eccf-1c5b1ea5c351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        }
      ],
      "source": [
        "API_ENDPOINT = (\n",
        "    f\"{TTS_LOCATION}-texttospeech.googleapis.com\"\n",
        "    if TTS_LOCATION != \"global\"\n",
        "    else \"texttospeech.googleapis.com\"\n",
        ")\n",
        "\n",
        "client = texttospeech.TextToSpeechClient(\n",
        "    client_options=ClientOptions(api_endpoint=API_ENDPOINT)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7WQQFp_RvGH"
      },
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pWrNWdV_RxGn"
      },
      "outputs": [],
      "source": [
        "def text_generator(text: str) -> Iterator[str]:\n",
        "    \"\"\"Split text into sentences to simulate streaming\"\"\"\n",
        "\n",
        "    # Use regex with positive lookahead to find sentence boundaries\n",
        "    # without consuming the space after the punctuation\n",
        "    sentences: list[str] = re.findall(r\"[^.!?]+[.!?](?:\\s|$)\", text + \" \")\n",
        "\n",
        "    # Yield each complete sentence\n",
        "    for sentence in sentences:\n",
        "        yield sentence.strip()\n",
        "\n",
        "    # Check if there's remaining text not caught by the regex\n",
        "    # (text without ending punctuation)\n",
        "    last_char_pos: int = 0\n",
        "    for sentence in sentences:\n",
        "        last_char_pos += len(sentence)\n",
        "\n",
        "    if last_char_pos < len(text.strip()):\n",
        "        remaining: str = text.strip()[last_char_pos:]\n",
        "        if remaining:\n",
        "            yield remaining.strip()\n",
        "\n",
        "\n",
        "def process_streaming_audio(\n",
        "    text: str,\n",
        "    voice: texttospeech.VoiceSelectionParams,\n",
        "    display_individual_chunks: bool = False,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Process text into speech using streaming TTS\"\"\"\n",
        "\n",
        "    # Generate sentences from text\n",
        "    sentences: list[str] = list(text_generator(text))\n",
        "\n",
        "    # Get streaming audio\n",
        "    print(\"Streaming audio processing...\")\n",
        "    audio_iterator: Iterator[bytes] = synthesize_streaming(iter(sentences), voice=voice)\n",
        "\n",
        "    # Process audio chunks\n",
        "    final_audio_data: np.ndarray = np.array([], dtype=np.int16)\n",
        "\n",
        "    for idx, audio_content in enumerate(audio_iterator):\n",
        "        audio_chunk: np.ndarray = np.frombuffer(audio_content, dtype=np.int16)\n",
        "\n",
        "        # Concatenate to final audio\n",
        "        final_audio_data = np.concatenate((final_audio_data, audio_chunk))\n",
        "\n",
        "        # Optionally display individual chunks\n",
        "        if display_individual_chunks and len(audio_chunk) > 0:\n",
        "            print(f\"Processed chunk # {idx}\")\n",
        "            display(Audio(audio_chunk, rate=24000))\n",
        "\n",
        "    print(\"Streaming audio processing complete!\")\n",
        "    return final_audio_data\n",
        "\n",
        "\n",
        "def synthesize_streaming(\n",
        "    text_iterator: Iterator[str],\n",
        "    voice: texttospeech.VoiceSelectionParams,\n",
        ") -> Iterator[bytes]:\n",
        "    \"\"\"Synthesizes speech from an iterator of text inputs and yields audio content as an iterator.\n",
        "\n",
        "    This function demonstrates how to use the Google Cloud Text-to-Speech API\n",
        "    to synthesize speech from a stream of text inputs provided by an iterator.\n",
        "    It yields the audio content from each response as an iterator of bytes.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    config_request = texttospeech.StreamingSynthesizeRequest(\n",
        "        streaming_config=texttospeech.StreamingSynthesizeConfig(\n",
        "            voice=voice,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def request_generator() -> Iterator[texttospeech.StreamingSynthesizeRequest]:\n",
        "        yield config_request\n",
        "        for text in text_iterator:\n",
        "            yield texttospeech.StreamingSynthesizeRequest(\n",
        "                input=texttospeech.StreamingSynthesisInput(text=text)\n",
        "            )\n",
        "\n",
        "    streaming_responses: Iterator[texttospeech.StreamingSynthesizeResponse] = (\n",
        "        client.streaming_synthesize(request_generator())\n",
        "    )\n",
        "\n",
        "    for response in streaming_responses:\n",
        "        yield response.audio_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPVDNRyVxquo"
      },
      "source": [
        "## Synthesize using Chirp 3 HD voices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9aa2ab365ac"
      },
      "source": [
        "### Synthesize speech using real-time (online) processing\n",
        "\n",
        "You define the text you want to convert, select a specific voice and language, and then instruct the API to generate an audio of the spoken text.\n",
        "\n",
        "This example uses the `en-US-Chirp3-HD-Aoede` voice, which is a high-definition voice, offering improved clarity. The code will call the `synthesize_speech` method, which handles the core conversion process, and the output will be an MP3 audio as `bytes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_7XwbSxUD4eW"
      },
      "outputs": [],
      "source": [
        "prompt = \"Hello world! I am Chirp 3\"  # @param [\"Hallo Welt! Ich bin Chirp 3\", \"Hello world! I am Chirp 3\", \"¡Hola mundo! Soy Chirp 3\", \"Bonjour le monde ! Je suis Chirp 3\", \"नमस्ते दुनिया! मैं चिर्प 3 हूं\", \"Olá Mundo! Eu sou o Chirp 3\", \"مرحبا بالعالم! أنا تشيرب 3\", \"¡Hola mundo! Soy Chirp 3\", \"Bonjour le monde ! Je suis Chirp 3\", \"Halo dunia! Saya Chirp 3\", \"Ciao mondo! Sono Chirp 3\", \"こんにちは世界！私はチャープ3です\", \"Merhaba dünya! Ben Chirp 3\", \"Chào thế giới! Tôi là Chirp 3\", \"হ্যালো ওয়ার্ল্ড! আমি চির্প 3\", \"હેલો વર્લ્ડ! હું ચિર્પ 3 છું\", \"ನಮಸ್ಕಾರ ಪ್ರಪಂಚ! ನಾನು ಚಿರ್ಪ್ 3\", \"ഹലോ വേൾഡ്! ഞാൻ ചിർപ് 3 ആണ്\", \"नमस्कार जग! मी चिरप 3 आहे\", \"வணக்கம் உலகம்! நான் சிர்ப் 3\", \"హలో వరల్డ్! నేను చిర్ప్ 3\", \"Hallo wereld! Ik ben Chirp 3\", \"안녕하세요! 저는 Chirp 3입니다\", \"你好世界！我是 Chirp 3\", \"Witaj świecie! Jestem Chirp 3\", \"Привет, мир! Я Чирп 3\", \"สวัสดีชาวโลก! ฉันคือเชิร์ป 3\"]\n",
        "\n",
        "voice = \"Aoede\"  # @param [\"Aoede\", \"Puck\", \"Charon\", \"Kore\", \"Fenrir\", \"Leda\", \"Orus\", \"Zephyr\"]\n",
        "\n",
        "language_code = \"en-US\"  # @param [ \"de-DE\", \"en-AU\", \"en-GB\", \"en-IN\", \"en-US\", \"fr-FR\", \"hi-IN\", \"pt-BR\", \"ar-XA\", \"es-ES\", \"fr-CA\", \"id-ID\", \"it-IT\", \"ja-JP\", \"tr-TR\", \"vi-VN\", \"bn-IN\", \"gu-IN\", \"kn-IN\", \"ml-IN\", \"mr-IN\", \"ta-IN\", \"te-IN\", \"nl-NL\", \"ko-KR\", \"cmn-CN\", \"pl-PL\", \"ru-RU\", \"th-TH\"]\n",
        "\n",
        "voice_name = f\"{language_code}-Chirp3-HD-{voice}\"\n",
        "voice = texttospeech.VoiceSelectionParams(\n",
        "    name=voice_name,\n",
        "    language_code=language_code,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "98d104dc4d27",
        "outputId": "87d2928b-49b6-4a7a-83c0-6837b8f5c4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionDenied",
          "evalue": "403 Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"texttospeech.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/764086051850\"\n}\n, locale: \"en-US\"\nmessage: \"Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.210.95:443 {created_time:\"2025-04-10T07:15:15.57593792+00:00\", grpc_status:7, grpc_message:\"Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bdbf2387147c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the text-to-speech request on the text input with the selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# voice parameters and audio file type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = client.synthesize_speech(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexttospeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSynthesisInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvoice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/texttospeech_v1beta1/services/text_to_speech/client.py\u001b[0m in \u001b[0;36msynthesize_speech\u001b[0;34m(self, request, input, voice, audio_config, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDenied\u001b[0m: 403 Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"texttospeech.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/764086051850\"\n}\n, locale: \"en-US\"\nmessage: \"Your application is authenticating by using local Application Default Credentials. The texttospeech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n]"
          ]
        }
      ],
      "source": [
        "# Perform the text-to-speech request on the text input with the selected\n",
        "# voice parameters and audio file type\n",
        "response = client.synthesize_speech(\n",
        "    input=texttospeech.SynthesisInput(text=prompt),\n",
        "    voice=voice,\n",
        "    # Select the type of audio file you want returned\n",
        "    audio_config=texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fad3a3de36d9"
      },
      "source": [
        "Play the generated audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e0881955f62"
      },
      "outputs": [],
      "source": [
        "display(Audio(response.audio_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYKj5gmDG7nT"
      },
      "source": [
        "### Synthesize speech using streaming processing\n",
        "\n",
        "Chirp 3 HD voices also support streaming text-to-speech conversion using the `streaming_synthesize` method.  Unlike the standard `synthesize_speech`, which handles single requests, `streaming_synthesize` processes continuous streams of text, generating corresponding audio streams.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HniB988UTUlq"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Google Cloud Text-to-Speech (TTS) is a powerful API that converts text into natural-sounding audio. Here's a breakdown:\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "* **High-Fidelity Speech:** Leverages advanced AI to generate speech that closely resembles human voices.\n",
        "* **Wide Voice Selection:** Offers a vast library of over 380 voices across 50+ languages and variants, catering to diverse needs.\n",
        "* **Customization Options:**\n",
        "    * **Custom Voice:** Create unique voices tailored to your brand or specific requirements using your own audio recordings.\n",
        "    * **SSML Support:** Utilize Speech Synthesis Markup Language (SSML) to control pronunciation, pacing, and other speech nuances.\n",
        "* **Integration Flexibility:** Easily integrate with various applications and devices via REST or gRPC APIs.\n",
        "* **Use Cases:**\n",
        "    * **Voice Assistants:** Powering conversational AI in smart devices, chatbots, and voice-activated applications.\n",
        "    * **Accessibility:** Enabling screen readers and text-to-speech features for users with disabilities.\n",
        "    * **E-learning:** Creating engaging and accessible educational content.\n",
        "    * **Audiobooks and Podcasts:** Producing high-quality audio for audiobooks, podcasts, and other audio content.\n",
        "    * **Interactive Experiences:** Enhancing user experiences in games, virtual reality, and other interactive applications.\n",
        "\n",
        "**In essence, Google Cloud Text-to-Speech empowers developers and businesses to:**\n",
        "\n",
        "* **Enhance user experiences:** Create more engaging and inclusive interactions through natural-sounding speech.\n",
        "* **Increase accessibility:** Make information more accessible to a wider audience, including those with visual impairments.\n",
        "* **Improve efficiency:** Automate tasks like reading aloud documents, generating voiceovers, and creating interactive voice responses.\n",
        "* **Innovate with new applications:** Explore novel use cases by leveraging the power of AI-powered speech synthesis.\n",
        "\n",
        "If you're looking to add a voice dimension to your applications or projects, Google Cloud Text-to-Speech is a valuable tool to consider.\n",
        "\"\"\"\n",
        "final_audio_data = process_streaming_audio(\n",
        "    prompt, voice, display_individual_chunks=False\n",
        ")\n",
        "\n",
        "display(Audio(final_audio_data, rate=24000))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started_with_chirp_3_hd_voices.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}